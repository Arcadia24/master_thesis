\section{Introduction}

\subsection{Context and overview}

Sound plays a fundamental role in human communication, enriching interactions by conveying not only explicit content but also a range of contextual information. Through voice, we communicate not only the subject matter of a conversation but also convey emotions, tone, and insights about the speaker’s identity—such as age, gender, or mood—through vocal characteristics. Research highlights that human speech transmits an extensive array of paralinguistic information, essential for creating empathy and understanding between speakers \cite{schuller2013paralinguistics}. This combination of explicit and implicit information enhances human interactions, making sound a uniquely powerful communication medium.

In contrast, Human-Computer Interaction (HCI) has traditionally relied on visual and text-based modalities, as images and text provide a straightforward and discreet means of information exchange, particularly in public or shared spaces. However, certain use cases demonstrate that sound-based interaction offers unique advantages. For instance, augmented reality (AR) environments benefit from audio's immersive potential, which can deepen user engagement and make digital elements feel more integrated into the real world \cite{yang2022audio}. Additionally, sound-based interaction supports accessibility by providing essential options for visually impaired users or those with limited physical interaction capability \cite{brock2015interactive}.

The potential for sound-based AI in HCI thus holds promise for enhancing and diversifying user experiences. Recent advances in artificial intelligence, particularly with deep learning, have transformed audio applications, allowing for more sophisticated implementations of Text-to-Speech (TTS) \cite{ren2020fastspeech}, Speech-to-Text (STT) \cite{inaguma2020espnet}, and audio classification models \cite{gemmeke2017audio}. These AI models have empowered systems to interpret and generate human speech in ways that were previously unattainable. In particular, generative models now enable dynamic vocal interactions that adapt in real time, moving beyond pre-recorded assets to create more authentic, flexible responses \cite{brown2020language}.




\subsection{Problem statement}

The main problem that this master thesis will focus on is :

\begin{center}
    \textbf{How can sensing technologies redefine our interactions with plants ?}\\
\end{center}

\subsection{Research domain}

\subsection{Contributions}

\begin{enumerate}

\end{enumerate}
