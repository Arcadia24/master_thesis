\section{Introduction}

\subsection{Context and overview}

Sound plays a fundamental role in human communication, enriching interactions by conveying not only explicit content but also a range of contextual information. Through voice, we communicate not only the subject matter of a conversation but also convey emotions, tone, and insights about the speaker’s identity—such as age, gender, or mood—through vocal characteristics. Research highlights that human speech transmits an extensive array of paralinguistic information, essential for creating empathy and understanding between speakers [Schuller et al., 2013]. This combination of explicit and implicit information enhances human interactions, making sound a uniquely powerful communication medium.

In contrast, Human-Computer Interaction (HCI) has traditionally relied on visual and text-based modalities, as images and text provide a straightforward and discreet means of information exchange, particularly in public or shared spaces. However, certain use cases demonstrate that sound-based interaction offers unique advantages. For instance, augmented reality (AR) environments benefit from audio's immersive potential, which can deepen user engagement and make digital elements feel more integrated into the real world [Davis et al., 2020]. Additionally, sound-based interaction supports accessibility by providing essential options for visually impaired users or those with limited physical interaction capability [González et al., 2017].
The potential for sound-based AI in HCI thus holds promise for enhancing and diversifying user experiences. Recent advances in artificial intelligence, particularly with deep learning, have transformed audio applications, allowing for more sophisticated implementations of Text-to-Speech (TTS) [Ren et al., 2020], Speech-to-Text (STT) [Li et al., 2020], and audio classification models [Gemmeke et al., 2017]. These AI models have empowered systems to interpret and generate human speech in ways that were previously unattainable. In particular, generative models now enable dynamic vocal interactions that adapt in real time, moving beyond pre-recorded assets to create more authentic, flexible responses [Brown et al., 2020].




\subsection{Problem statement}

The main problem that this master thesis will focus on is :

\begin{center}
    \textbf{How can sensing technologies redefine our interactions with plants ?}\\
\end{center}

\subsection{Research domain}

The study of human-plant interaction covers a broad spectrum of research areas. This master's thesis focuses on the Human-Computer Interaction (HCI) field, which examines the interfaces between people and computers. HCI sits "at the intersection between psychology and social sciences, on the one hand, and computer science and technology, on the other," \cite{carrollHUMANCOMPUTERINTERACTIONPsychology} providing insights into how humans interact with technology.

In this thesis, the concept of interaction is extended to plants and nature, aiming to enhance plant capabilities and explore how plants can be used as interactive elements. By transforming plants into living sensors, the research also intersects with the fields of instrumentation engineering and electronics. These fields focus on developing new ways of capturing data to design functional sensors. Understanding plants as bio-living sensors requires the application of specific sensing techniques to access their natural abilities.

Additionally, this work involves the sensor development field, where plants are converted into functional sensors. This transformation represents an innovative approach to expanding the possibilities of plant-based sensing technologies.


\subsection{Contributions}

This thesis makes several contributions to the field of Human-Computer Interaction and sensor technologies:

\begin{enumerate}
    \item \textbf{Development of Plant-based Bio-sensors and Sound Interaction System}: This thesis introduces a novel system that transforms plants into living bio-sensors, utilizing their natural sensing capabilities to capture human-plant interactions. The data collected from plant sensors is used to generate real-time auditory feedback, creating an innovative, sound-based interaction mechanism. This approach opens up new avenues for exploring plant interactions in both technological and artistic contexts.
    \item \textbf{Creation of a Network of Plant Sensors for Distributed Interaction}: In addition to the single-plant sensor system, this research extends the concept by developing a network of interconnected plant-based sensors. This network allows for distributed sensing and interaction across multiple plants, enabling more complex data collection and processing. The system demonstrates potential applications in human-computer interaction, environmental monitoring, and artistic installations, highlighting its multidisciplinary impact.
\end{enumerate}
