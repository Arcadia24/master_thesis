\section{Conclusion}
This thesis explored the intersection of sound-based artificial intelligence, TTS synthesis, and AR to develop innovative applications aimed at enhancing human-computer interaction and immersive learning experiences. Each project focused on a unique application area, from bird species classification to emotionally expressive TTS, culminating in the creation of an interactive AR platform for theater training. Together, these projects demonstrate the versatility and potential of sound-based AI to enable meaningful, responsive interactions in diverse settings.

The first project developed a robust classifier for identifying bird species through their vocalizations, addressing challenges in species generalization and optimizing real-time audio processing. This work highlighted how sound AI  can support environmental monitoring efficiently and in an accessible way with a user-friendly interface.

The second project extended these capabilities by synthesizing emotionally adaptive TTS, capable of generating speech with distinct emotional expressions. This system used FastSpeech2 and emotion conversion model to produce emotionally resonant audio, allowing for more lifelike and relatable interactions with virtual agents. The project underscored the potential of TTS to improve human-computer interaction.

Building on these foundations, the third project implemented an AR-based theater training application where students could interact with virtual characters capable of emotion-driven responses when their is less students than character in the theatre's piece. Through the integration on a GOSAIâ€™s AR framework, the application provided a responsive, immersive environment for students to practice performance skills. This work show new perspective for Sound-AI in Human-Computer Interaction and in educational technology for the performing arts.

This thesis establishes a pathway for integrating sound-based AI into various interactive domains, from bioacoustics to education and performance arts. These contributions underscore the transformative potential of adaptive AI and AR in creating engaging, responsive user experiences, paving the way for further advancements in immersive and accessible technology applications.