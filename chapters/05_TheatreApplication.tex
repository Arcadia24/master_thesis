\section{Theatre Application}

\subsection{Introduction}

Here’s a revised Introduction that incorporates the additional information provided:

Introduction
The Theatre Learning project, set on the Second Self AR platform, introduces an innovative augmented reality (AR) application designed to enhance theater education. The platform functions as an "augmented mirror," creating an immersive environment where students can interact with virtual characters that respond in real time. This AR experience is powered by GOSAI, an AR framework widely used for developing proof-of-concept (POC) applications and facilitating research in interactive and immersive technologies.

In this application, the integration of audio plays a central role, allowing virtual characters to interact with users via expressive, synthesized speech. The characters can speak lines, provide feedback, and engage in conversation, bridging the gap for scenarios where real actors are unavailable. Emotionally adaptive Text-to-Speech (TTS) technology enables these characters to deliver lines with varying tones and emotions, enriching the realism and engagement of the training experience. Speech-to-Text (STT) components are also included, providing feedback to students as they perform, enhancing their practice by analyzing spoken input and providing guidance based on real-time interactions.

My primary contribution to this project is the integration of an immersive TTS system, designed to serve as a replacement for live actors when they are not present. By enabling virtual characters to speak with realistic emotion and expression, this TTS system allows students to experience meaningful, responsive interactions. The project ultimately aims to offer students a dynamic, interactive space to practice and refine their performance skills, combining the best of traditional theater education with the possibilities of AR and adaptive AI.

State of the Art
Applications in Learning
The integration of technology into educational settings has transformed how learners engage with material, particularly in fields requiring hands-on practice and experiential learning. Interactive applications that use simulations, virtual reality (VR), and augmented reality (AR) enable students to actively participate in learning experiences that closely mimic real-life situations. These applications are especially impactful in domains where physical practice is constrained by costs, safety, or logistical limitations, such as medicine, language acquisition, and the performing arts [Dede, 2009; Jensen & Konradsen, 2018].

Within these applications, Speech-to-Text (STT) and Text-to-Speech (TTS) technologies play a crucial role in facilitating interactive, personalized learning. STT systems allow learners to receive immediate feedback on pronunciation, fluency, or emotional tone, which is essential in fields like language learning and theater training [Li et al., 2020]. By analyzing learners' vocal inputs, STT provides real-time insights into performance, helping students make adjustments on the fly. Meanwhile, TTS technology enhances the interactivity of these applications by allowing virtual characters or instructors to respond in a lifelike manner, simulating human conversation and improving the realism of the training environment [Wik & Hjalmarsson, 2009]. These technologies have proven effective in providing tailored feedback, which can improve skill acquisition and confidence over time.

In theater and performing arts, where practice traditionally involves real-time interaction with live instructors or other actors, adaptive TTS and STT technologies offer a flexible solution. They allow learners to rehearse dialogue, receive feedback, and experiment with emotional expression in a supportive, iterative manner. For instance, TTS systems can simulate different character responses based on the learner's delivery, encouraging learners to adapt and refine their performance [Kory-Westlund et al., 2017]. By providing adaptive, immersive feedback, these technologies help bridge the gap between individual practice and collaborative performance, offering learners the opportunity to develop their craft in an engaging, technology-enhanced environment.

AR Applications for Learning
Augmented Reality (AR) has also found a significant place in educational settings, particularly in applications where spatial awareness, contextual understanding, and interactivity are essential. Unlike VR, which creates a fully virtual environment, AR overlays digital information onto the physical world, allowing learners to see and interact with virtual objects within their actual surroundings. This approach makes AR particularly useful for subjects that benefit from spatial context and visualization, such as anatomy in medical education, mechanical engineering, and language acquisition [Akçayır & Akçayır, 2017].

Research shows that AR applications in education promote higher engagement and retention by allowing learners to manipulate and explore content in a hands-on way. For instance, in language learning, AR applications may use contextualized vocabulary practice by overlaying words onto physical objects, creating a more intuitive, immersive experience [Chun et al., 2020]. Similarly, AR applications in science and technical fields allow students to visualize complex structures, processes, or data points in three dimensions, which can be especially valuable for learners who benefit from interactive, kinesthetic learning experiences [Santos et al., 2016].

In the field of theater, AR offers unique potential to simulate stage dynamics, spatial relationships, and character interactions in real-time. Theater training requires skills beyond memorizing lines—actors must also master timing, movement, and emotional expression in response to other characters and the physical space around them. AR applications that incorporate emotionally adaptive TTS and STT can provide a responsive, interactive environment where students can practice these skills without needing live partners [Mavrikios et al., 2013]. By using TTS to give virtual characters lifelike voices and personalities, AR systems can simulate full scenes and character interactions, offering students a realistic stage environment in which to refine their craft.

The potential of AR for theater training lies in its ability to blend the digital and physical worlds, creating a virtual stage where characters interact and respond as real actors would. In an AR-enhanced theater learning setting, students can engage with virtual characters that adapt their emotional tone and responses based on user input, providing a more comprehensive training experience. Such applications extend beyond basic line practice, allowing learners to develop expressive and technical skills critical for theater, such as interpreting cues, adjusting timing, and delivering emotionally resonant performances. Integrating AR and adaptive TTS into theater training represents a significant step forward in education technology, enabling students to experience authentic, interactive rehearsal environments that closely mimic real-world conditions.

Project Explanation
The Theatre Learning project is built upon the Second Self AR platform, which serves as an “augmented mirror” that enables users to interact with virtual characters embedded within their physical space. This application’s AR foundation creates an immersive training environment for theater students, allowing them to practice timing, voice modulation, and emotional expression by engaging with responsive, emotionally adaptive digital characters.

The platform operates on GOSAI, a flexible AR framework developed for rapid prototyping and proof-of-concept (POC) applications, particularly suited for research purposes. GOSAI’s modular architecture provides a robust foundation for integrating multiple components—including audio processing, AR visualization, and real-time user interaction—into a cohesive system. With a Python-based backend managing data flow and interaction, GOSAI enables the Theater Learning application to handle complex, latency-sensitive processes essential for real-time interaction in an educational setting.

My Contribution
My primary role in this project focuses on the integration and optimization of a Text-to-Speech (TTS) module that brings virtual characters to life through expressive, synthesized speech. The TTS system, built with FastSpeech2 and HiFi-GAN, generates high-quality, emotionally adaptive speech to serve as a stand-in for live actors when they are unavailable. This system can adjust tone, pitch, and pacing based on character context, allowing students to practice lines, receive feedback, and interact as though they were performing alongside a real actor.

Additionally, the TTS system is integrated with a real-time Speech-to-Text (STT) component, which provides instant feedback to students based on their vocal performance. As students practice, the STT system analyzes their speech, offering feedback and guidance to help them refine elements such as delivery and emotional intensity. By automating these feedback mechanisms, the Theatre Learning platform enables self-directed practice, empowering students to work independently or receive supplementary practice outside of scheduled instruction.

Interaction Flow and Capabilities
The Theatre Learning application offers a variety of interactive options for students. As they engage with virtual characters, students can practice scripted scenes or improvisational dialogues, receiving contextually appropriate responses from the TTS-driven characters. The characters adapt their emotional expressions in response to the user’s performance, creating a responsive, lifelike training environment. This adaptability is crucial in theater training, where students must learn to respond to subtle changes in tone, timing, and emotion.

The system also supports gesture-based interaction and spatial audio cues. For instance, as students move closer to or further from a virtual character, the character’s voice adjusts in volume and positioning, adding a layer of spatial awareness to the interaction. Students may also use gestures to initiate or halt interactions, making the AR experience intuitive and interactive.

In summary, this project leverages the GOSAI framework’s modular architecture to deliver a realistic, immersive theater training experience. Through the integration of emotionally adaptive TTS, STT feedback, and spatial interactivity, the Theatre Learning platform provides a versatile tool for students to practice critical performance skills in a controlled yet dynamic environment.

Discussion
The Theatre Learning project has demonstrated the potential of augmented reality (AR) combined with emotionally adaptive TTS (Text-to-Speech) and STT (Speech-to-Text) technology to create an interactive and immersive training environment for theater students. By enabling students to engage with virtual characters capable of realistic emotional responses, this platform allows for effective self-guided practice, complementing traditional theater instruction.

The project’s success in providing a realistic, responsive experience underscores the effectiveness of using AR to simulate real-world settings, especially in disciplines like theater where practice and experiential learning are crucial. The system’s ability to deliver real-time emotional responses via optimized TTS enhances the authenticity of student interactions, fostering a learning environment that closely resembles in-person practice. Additionally, STT-based feedback offers students real-time guidance, enabling them to adjust their performances dynamically based on system-generated cues.

However, certain limitations remain. Although the TTS system performs well in general, replicating complex emotional responses, such as highly intense or subtle expressions, is challenging. Intense emotions often involve rapid tonal shifts and specific pacing, which the current TTS configuration cannot always replicate with perfect fidelity. Additionally, the reliance on emotion recognition means that ambiguous or complex user inputs could occasionally lead to less accurate or mismatched responses from the virtual characters, potentially disrupting immersion.

Future work could focus on refining the TTS system for greater emotional accuracy in high-intensity scenarios and enhancing the precision of the emotion recognition module. Another potential improvement involves expanding the range of supported gestures and expressions to allow for more nuanced interactions, making the virtual characters more adaptable to a wider range of theatrical practices. Introducing support for multi-character scenes and collaborative AR settings could also further enrich the experience, simulating more complex performance scenarios and group rehearsals.

Conclusion
The Theatre Learning project has successfully created a foundation for interactive theater training, utilizing AR, TTS, and STT to provide students with a versatile tool for practicing and refining performance skills. By simulating realistic character interactions in an augmented reality environment, the system offers an engaging way for students to work on timing, emotional expression, and voice modulation. This platform represents an innovative approach to theater education, bridging technology with performing arts to enhance traditional learning methods.

This project highlights the value of adaptive TTS and AR in education technology, pointing to a future where students can practice critical skills in immersive environments that closely mimic real-world interactions. While challenges remain, this project establishes a pathway for integrating advanced interaction technologies into arts education, with potential applications across a range of experiential learning disciplines.

